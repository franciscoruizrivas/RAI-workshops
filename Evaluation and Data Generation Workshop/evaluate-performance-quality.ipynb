{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Using Performance & Quality Metrics\n",
    "\n",
    "Contoso Home Furnishings is developing an app that generates product descriptions for their selection of furniture. The app aims to generate engaging product descriptions based on the manufacturer's specification of the furniture.\n",
    "\n",
    "In this exercise, you will evaluate the model output for the generated product description using performance and quality metrics. Provided below is an example of a row of data provided for the description generated for the Contoso Home Furnishings Dining Chair:\n",
    "\n",
    "`context`\n",
    "\n",
    "Dining chair. Wooden seat. Four legs. Backrest. Brown. 18\" wide, 20\" deep, 35\" tall. Holds 250 lbs.\n",
    "\n",
    "`query`\n",
    "\n",
    "Given the product specfication for the Contoso Home Furnishings Dining Chair, provide a product description.\n",
    "\n",
    "`ground_truth`\n",
    "\n",
    "The dining chair is brown and wooden with four legs and a backrest. The dimensions are 18\" wide, 20\" deep, 35\" tall. The dining chair has a weight capacity of 250 lbs.\n",
    "\n",
    "`response`\n",
    "\n",
    "Introducing our timeless wooden dining chair, designed for both comfort and durability. Crafted with a solid wood seat and sturdy four-legged base, this chair offers reliable support for up to 250 lbs. The smooth brown finish adds a touch of rustic elegance, while the ergonomically shaped backrest ensures a comfortable dining experience. Measuring 18\" wide, 20\" deep, and 35\" tall, it's the perfect blend of form and function, making it a versatile addition to any dining space. Elevate your home with this beautifully simple yet sophisticated seating option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add environment variables to the .env file\n",
    "\n",
    "In the root of the **Evaluation and Data Generation Workshop** folder is an `.env` file. Within the `.env` file, fill in the values for the environment variables. You can locate the values for each environment variable in the following locations of the [Azure AI Foundry](https://ai.azure.com) portal:\n",
    "\n",
    "- `AZURE_SUBSCRIPTION_ID` - On the **Overview** page of your project within **Project details**.\n",
    "- `AZURE_AI_PROJECT_NAME` - At the top of the **Overview** page for your project.\n",
    "- `AZURE_OPENAI_RESOURCE_GROUP` - On the **Overview** page of the **Management Center** within **Project properties**.\n",
    "- `AZURE_OPENAI_SERVICE` - On the **Overview** page of your project in the **Included capabilities** tab for **Azure OpenAI Service**.\n",
    "- `AZURE_OPENAI_API_VERSION` - On the [API version lifecycle](https://learn.microsoft.com/azure/ai-services/openai/api-version-deprecation#latest-ga-api-release) webpage within the **Latest GA API release** section.\n",
    "- `AZURE_OPENAI_ENDPOINT` - On the **Details** tab of your model deployment within **Endpoint** (i.e. **Target URI**)\n",
    "- `AZURE_OPENAI_DEPLOYMENT_NAME` -  On the **Details** tab of your model deployment within **Deployment info**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign in to Azure\n",
    "\n",
    "As a security best practice, we'll use [keyless authentication](https://learn.microsoft.com/azure/developer/ai/keyless-connections?tabs=csharp%2Cazure-cli) to authenticate to Azure OpenAI with Microsoft Entra ID. Before you can do so, you'll first need to install the **Azure CLI** per the [installation instructions](https://learn.microsoft.com/cli/azure/install-azure-cli) for your operating system.\n",
    "\n",
    "Next, open a terminal and run `az login` to sign in to your Azure account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the package\n",
    "\n",
    "The evaluator classes for assessing performance and quality are in the Azure AI Evaluation SDK. We'll begin by installing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: azure-ai-evaluation in /home/vscode/.local/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: promptflow-devkit>=1.17.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (1.18.1)\n",
      "Requirement already satisfied: promptflow-core>=1.17.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (1.18.1)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (2.10.1)\n",
      "Requirement already satisfied: azure-identity>=1.16.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (1.23.0)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (1.35.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (12.25.1)\n",
      "Requirement already satisfied: httpx>=0.25.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (2.3.0)\n",
      "Requirement already satisfied: openai>=1.78.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (1.93.0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (0.18.14)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.6 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.20.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.4)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.14.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (45.0.5)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.7.2)\n",
      "Requirement already satisfied: anyio in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in /home/vscode/.local/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/vscode/.local/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/vscode/.local/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.78.0->azure-ai-evaluation) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.78.0->azure-ai-evaluation) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\n",
      "Requirement already satisfied: docstring_parser in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.115.14)\n",
      "Requirement already satisfied: filetype>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (4.24.0)\n",
      "Requirement already satisfied: promptflow-tracing==1.18.1 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.18.1)\n",
      "Requirement already satisfied: psutil in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (7.0.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-tracing==1.18.1->promptflow-core>=1.17.1->azure-ai-evaluation) (1.34.1)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-tracing==1.18.1->promptflow-core>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.6.2)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.0b39)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.18.0)\n",
      "Requirement already satisfied: flask-cors<7.0.0,>=6.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.0.1)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in /usr/local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.41)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.26.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.1)\n",
      "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (11.0.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.1.1)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (2.0.41)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/vscode/.local/lib/python3.11/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.12)\n",
      "Requirement already satisfied: fixedint==0.1.6 in /home/vscode/.local/lib/python3.11/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.26 in /home/vscode/.local/lib/python3.11/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.1)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/vscode/.local/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/vscode/.local/lib/python3.11/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.46.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (2.2.0)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.3)\n",
      "Requirement already satisfied: aniso8601>=0.82 in /home/vscode/.local/lib/python3.11/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.0.1)\n",
      "Requirement already satisfied: importlib-resources in /home/vscode/.local/lib/python3.11/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.5.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.12)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.26.0)\n",
      "Requirement already satisfied: jaraco.classes in /home/vscode/.local/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.11.4 in /home/vscode/.local/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (8.7.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/vscode/.local/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/vscode/.local/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vscode/.local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (25.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.1)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.29.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.3.1)\n",
      "Requirement already satisfied: greenlet>=1 in /home/vscode/.local/lib/python3.11/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.2.3)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/vscode/.local/lib/python3.11/site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.18.1->promptflow-core>=1.17.1->azure-ai-evaluation) (0.55b1)\n",
      "Requirement already satisfied: more-itertools in /home/vscode/.local/lib/python3.11/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the environment variables.\n",
    "\n",
    "We'll import `os` and `load_dotenv` so that you can access the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup keyless authentication\n",
    "\n",
    "Rather than hardcode your **key**, we'll use a keyless connection with Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.identity\n",
    "\n",
    "credential = azure.identity.DefaultAzureCredential()\n",
    "token_provider = azure.identity.get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "token = token_provider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the model_config\n",
    "\n",
    "The `model_config` is necessary as it's a required parameter when creating an instance of the evaluator class. Let's configure the `model_config` with the following:\n",
    "\n",
    "- Azure OpenAI endpoint\n",
    "- Azure OpenAI API key\n",
    "- Azure deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": token,\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create variables for the evaluation data\n",
    "\n",
    "Since we'll be using the same context, query, response, and ground truth for the exercises, we'll create a variable to store each string and pass the variables into our evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Dining chair. Wooden seat. Four legs. Backrest. Brown. 18\\\" wide, 20\\\" deep, 35\\\" tall. Holds 250 lbs.\"\n",
    "query = \"Given the product specification for the Contoso Home Furnishings Dining Chair, provide an engaging marketing product description.\"\n",
    "ground_truth = \"The dining chair is brown and wooden with four legs and a backrest. The dimensions are 18\\\" wide, 20\\\" deep, 35\\\" tall. The dining chair has a weight capacity of 250 lbs.\"\n",
    "response = \"Introducing our timeless wooden dining chair, designed for both comfort and durability. Crafted with a solid wood seat and sturdy four-legged base, this chair offers reliable support for up to 250 lbs. The smooth brown finish adds a touch of rustic elegance, while the ergonomically shaped backrest ensures a comfortable dining experience. Measuring 18\\\" wide, 20\\\" deep, and 35\\\" tall, it's the perfect blend of form and function, making it a versatile addition to any dining space. Elevate your home with this beautifully simple yet sophisticated seating option.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Groundedness\n",
    "\n",
    "Create an instance of the `GroundednessEvaluator` and run the evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Could not import AIAgentConverter. Please install the dependency with `pip install azure-ai-projects`.\n",
      "[INFO] Could not import SKAgentConverter. Please install the dependency with `pip install semantic-kernel`.\n",
      "{'groundedness': 3.0, 'gpt_groundedness': 3.0, 'groundedness_reason': 'The RESPONSE is accurate in conveying the details from the CONTEXT but introduces unsupported additions, making it grounded but not fully faithful to the source material.', 'groundedness_result': 'pass', 'groundedness_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "\n",
    "groundedness_score = groundedness_eval(\n",
    "    response=response,\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "print(groundedness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Relevance\n",
    "\n",
    "Create an instance of the `RelevanceEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 5.0, 'gpt_relevance': 5.0, 'relevance_reason': 'The RESPONSE fully addresses the QUERY with accurate and complete information, while also adding relevant insights to make the description engaging and appealing for marketing purposes.', 'relevance_result': 'pass', 'relevance_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "\n",
    "relevance_score = relevance_eval(\n",
    "    response=response,\n",
    "    context=context,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "print(relevance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Coherence\n",
    "\n",
    "Create an instance of the `CoherenceEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The RESPONSE is coherent, effectively addressing the QUERY with a clear and logical presentation of ideas. It provides all relevant details in an engaging manner, making it suitable for marketing purposes.', 'coherence_result': 'pass', 'coherence_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "\n",
    "coherence_score = coherence_eval(\n",
    "    response=response,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "print(coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Fluency\n",
    "\n",
    "Create an instance of the `FluencyEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fluency': 5.0, 'gpt_fluency': 5.0, 'fluency_reason': 'The RESPONSE is articulate, cohesive, and uses sophisticated language with varied sentence structures, making it highly readable and engaging. It reflects a high level of fluency and style.', 'fluency_result': 'pass', 'fluency_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "\n",
    "fluency_score = fluency_eval(\n",
    "    response=response,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "print(fluency_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Similarity\n",
    "\n",
    "Create an instance of the `SimiliartyEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'similarity': 5.0, 'gpt_similarity': 5.0, 'similarity_result': 'pass', 'similarity_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import SimilarityEvaluator\n",
    "\n",
    "similarity_eval = SimilarityEvaluator(model_config)\n",
    "\n",
    "similarity_score = similarity_eval(\n",
    "    response=response,\n",
    "    query=query,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for F1 Score\n",
    "\n",
    "Create an instance of the `F1ScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.35185185185185186, 'f1_result': 'fail', 'f1_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import F1ScoreEvaluator\n",
    "\n",
    "f1_eval = F1ScoreEvaluator()\n",
    "\n",
    "f1_score = f1_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for ROUGE\n",
    "There are several types of ROUGE metrics: `ROUGE_1`, `ROUGE_2`, `ROUGE_3`, `ROUGE_4`, `ROUGE_5`, and `ROUGE_L`.\n",
    "\n",
    "The initial 5 types are considered **ROUGE-N** which measures the overlap of n-grams (contiguous sequences of 'n' words) between the generated summary and reference summary. For example, `ROUGE_1` measures of the overalp of unigrams (single words), and `ROUGE_2` measures the overlap of bigrams (two-word sequences). We provide up to 5-grams.\n",
    "\n",
    "`ROUGE_L` measures the longest common subsequence (LCS) between the generated and reference summaries. LCS takes into account sequence similarity whle maintaining word order, which makes `ROUGE_L` effective in capturing sentence-level structure.\n",
    "\n",
    "Create an instance of the `RougeScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_precision': 0.2777777777777778, 'rouge_recall': 0.78125, 'rouge_f1_score': 0.40983606557377056, 'rouge_precision_result': 'fail', 'rouge_recall_result': 'pass', 'rouge_f1_score_result': 'fail', 'rouge_precision_threshold': 0.5, 'rouge_recall_threshold': 0.5, 'rouge_f1_score_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
    "\n",
    "rouge_eval = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)\n",
    "\n",
    "rouge_score = rouge_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(rouge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for BLEU\n",
    "\n",
    "Create an instance of the `BleuScoreEvaluator` and run the evaluation.\n",
    "\n",
    "**Note**: The initial run may install a package. If this occurs, run the cell once more to receive the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu_score': 0.10903931692423613, 'bleu_result': 'fail', 'bleu_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import BleuScoreEvaluator\n",
    "\n",
    "bleu_eval = BleuScoreEvaluator()\n",
    "\n",
    "bleu_score = bleu_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for METEOR\n",
    "\n",
    "The METEOR metric takes an `alpha`, `beta`, and `gamma` parameter which control the balance between precision, recall, and the penalty for incorrect word order (fragmentation penalty). These parameters influence how the final METEOR score is calculated, helping fine-tune it's sensitivity to different aspects of the translation or summary quality.\n",
    "\n",
    "Create an instance of the `MeteorScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meteor_score': 0.5252285661368535, 'meteor_result': 'pass', 'meteor_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import MeteorScoreEvaluator\n",
    "\n",
    "meteor_eval = MeteorScoreEvaluator(\n",
    "    alpha=0.9,\n",
    "    beta=3.0,\n",
    "    gamma=0.5\n",
    ")\n",
    "\n",
    "meteor_score = meteor_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(meteor_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for GLEU\n",
    "\n",
    "Create an instance of the `GleuScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gleu_score': 0.13658536585365855, 'gleu_result': 'fail', 'gleu_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GleuScoreEvaluator\n",
    "\n",
    "gleu_eval = GleuScoreEvaluator()\n",
    "\n",
    "gleu_score = gleu_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(gleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on a test dataset\n",
    "\n",
    "We can run an evaluation for a dataset with the `evaluate` function. In addition, we can run the evaluation using multiple evaluators. In our case, we're going to run an evaluation using a few evaluators on the product description dataset within the `product-descriptions.jsonl` file. We'll also output the results to a new `evaluation_results.json` file.\n",
    "\n",
    "Let's run an evalation using the `Relevance`, `Groundedness`, and `Fluency` evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-03 16:11:51 +0000][promptflow][WARNING] - Found existing /workspaces/RAI-workshops/Evaluation and Data Generation Workshop/flow.flex.yaml, will not respect it in runtime.\n",
      "[2025-07-03 16:11:51 +0000][promptflow][WARNING] - Found existing /workspaces/RAI-workshops/Evaluation and Data Generation Workshop/flow.flex.yaml, will not respect it in runtime.\n",
      "[2025-07-03 16:11:51 +0000][promptflow][WARNING] - Found existing /workspaces/RAI-workshops/Evaluation and Data Generation Workshop/flow.flex.yaml, will not respect it in runtime.\n",
      "[2025-07-03 16:11:52 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-03 16:11:52 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-03 16:11:52 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_relevance_20250703_161151_983343, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250703_161151_983343/logs.txt\n",
      "[2025-07-03 16:11:52 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_fluency_20250703_161151_983952, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250703_161151_983952/logs.txt\n",
      "[2025-07-03 16:11:52 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-03 16:11:52 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250703_161151_983710, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250703_161151_983710/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-03 16:11:52 +0000   12649 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 2.53 seconds. Estimated time for incomplete lines: 5.06 seconds.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.35 seconds. Estimated time for incomplete lines: 1.35 seconds.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 0.96 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_fluency_20250703_161151_983952\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-07-03 16:11:51.994508+00:00\"\n",
      "Duration: \"0:00:03.120772\"\n",
      "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250703_161151_983952\"\n",
      "\n",
      "2025-07-03 16:11:52 +0000   12649 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 2.43 seconds. Estimated time for incomplete lines: 4.86 seconds.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.34 seconds. Estimated time for incomplete lines: 1.34 seconds.\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_relevance_20250703_161151_983343\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-07-03 16:11:51.993242+00:00\"\n",
      "Duration: \"0:00:03.168108\"\n",
      "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250703_161151_983343\"\n",
      "\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.06 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-03 16:11:52 +0000   12649 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 2.39 seconds. Estimated time for incomplete lines: 4.78 seconds.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-07-03 16:11:54 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.23 seconds. Estimated time for incomplete lines: 1.23 seconds.\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-07-03 16:11:55 +0000   12649 execution.bulk     INFO     Average execution time for completed lines: 1.06 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_groundedness_20250703_161151_983710\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-07-03 16:11:51.992583+00:00\"\n",
      "Duration: \"0:00:04.175716\"\n",
      "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250703_161151_983710\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"relevance\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:03.168108\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250703_161151_983343\"\n",
      "    },\n",
      "    \"groundedness\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:04.175716\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250703_161151_983710\"\n",
      "    },\n",
      "    \"fluency\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:03.120772\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250703_161151_983952\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'fluency.binary_aggregate': 1.0,\n",
      "             'fluency.fluency': 4.333333333333333,\n",
      "             'fluency.fluency_threshold': 3.0,\n",
      "             'fluency.gpt_fluency': 4.333333333333333,\n",
      "             'groundedness.binary_aggregate': 1.0,\n",
      "             'groundedness.gpt_groundedness': 3.0,\n",
      "             'groundedness.groundedness': 3.0,\n",
      "             'groundedness.groundedness_threshold': 3.0,\n",
      "             'relevance.binary_aggregate': 1.0,\n",
      "             'relevance.gpt_relevance': 3.6666666666666665,\n",
      "             'relevance.relevance': 3.6666666666666665,\n",
      "             'relevance.relevance_threshold': 3.0},\n",
      " 'rows': [{'inputs.context': 'Couch. Fabric upholstery. Three seats. Wooden '\n",
      "                             'frame. Grey. 85\" wide, 35\" deep, 32\" tall. Holds '\n",
      "                             '750 lbs.',\n",
      "           'inputs.ground_truth': 'The couch has a wood frame with gray '\n",
      "                                  'upholstered fabric. There are 3 seats on '\n",
      "                                  'the couch which can accommodate 750 lbs. '\n",
      "                                  'The dimensions are 85\" wide, 35\" deep, 32\" '\n",
      "                                  'tall.',\n",
      "           'inputs.query': 'Given the product specfication for the Contoso '\n",
      "                           'Home Furnishings Couch, provide a product '\n",
      "                           'description.',\n",
      "           'inputs.response': 'Sink into comfort with this stylish grey '\n",
      "                              'three-seater couch. Wrapped in soft, durable '\n",
      "                              'fabric upholstery and supported by a sturdy '\n",
      "                              \"wooden frame, it's designed for long-lasting \"\n",
      "                              'relaxation. Its sleek silhouette and neutral '\n",
      "                              'tone make it a versatile addition to any living '\n",
      "                              \"room, whether you're lounging solo or \"\n",
      "                              'entertaining guests. With its spacious 85-inch '\n",
      "                              \"width and 750 lbs weight capacity, it's both \"\n",
      "                              'practical and inviting.',\n",
      "           'outputs.fluency.fluency': 4,\n",
      "           'outputs.fluency.fluency_reason': 'The RESPONSE is '\n",
      "                                             'well-articulated, coherent, and '\n",
      "                                             'grammatically accurate, with '\n",
      "                                             'varied vocabulary and complex '\n",
      "                                             'sentence structures. It '\n",
      "                                             'effectively conveys the intended '\n",
      "                                             'message with minor stylistic '\n",
      "                                             'enhancements but does not '\n",
      "                                             'exhibit the exceptional '\n",
      "                                             'eloquence or sophistication '\n",
      "                                             'required for the highest score.',\n",
      "           'outputs.fluency.fluency_result': 'pass',\n",
      "           'outputs.fluency.fluency_threshold': 3,\n",
      "           'outputs.fluency.gpt_fluency': 4,\n",
      "           'outputs.groundedness.gpt_groundedness': 3,\n",
      "           'outputs.groundedness.groundedness': 3,\n",
      "           'outputs.groundedness.groundedness_reason': 'The RESPONSE is '\n",
      "                                                       'grounded in the '\n",
      "                                                       'CONTEXT but includes '\n",
      "                                                       'unsupported additions '\n",
      "                                                       'that are not directly '\n",
      "                                                       'derived from the '\n",
      "                                                       'provided information.',\n",
      "           'outputs.groundedness.groundedness_result': 'pass',\n",
      "           'outputs.groundedness.groundedness_threshold': 3,\n",
      "           'outputs.relevance.gpt_relevance': 4,\n",
      "           'outputs.relevance.relevance': 4,\n",
      "           'outputs.relevance.relevance_reason': 'The RESPONSE fully addresses '\n",
      "                                                 'the QUERY with all essential '\n",
      "                                                 'details required for a '\n",
      "                                                 'comprehensive understanding '\n",
      "                                                 'of the product, including '\n",
      "                                                 'its features, dimensions, '\n",
      "                                                 'and practical use. It does '\n",
      "                                                 'not add extraneous '\n",
      "                                                 'information but provides a '\n",
      "                                                 'complete and relevant '\n",
      "                                                 'description.',\n",
      "           'outputs.relevance.relevance_result': 'pass',\n",
      "           'outputs.relevance.relevance_threshold': 3},\n",
      "          {'inputs.context': 'Coffee table. Glass top. Metal frame. Round. '\n",
      "                             'Black finish. 30\" diameter, 18\" tall.',\n",
      "           'inputs.ground_truth': 'The coffee table has a metal frame and '\n",
      "                                  'glass top. The color is black. The '\n",
      "                                  'dimensions are 30\" diameter, 18\" tall.',\n",
      "           'inputs.query': 'Given the product specfication for the Contoso '\n",
      "                           'Home Furnishings Coffee Table, provide a product '\n",
      "                           'description.',\n",
      "           'inputs.response': 'Elevate your living space with this modern '\n",
      "                              'round coffee table, featuring a sleek glass top '\n",
      "                              'and sturdy black metal frame. The minimalist '\n",
      "                              'design pairs perfectly with contemporary decor, '\n",
      "                              'while the 30-inch diameter offers ample space '\n",
      "                              'for your books, decor, or coffee mugs. At 18 '\n",
      "                              \"inches tall, it's just the right height to \"\n",
      "                              'complement your seating arrangement. Simple yet '\n",
      "                              'sophisticated, this table adds a touch of '\n",
      "                              'elegance to any room.',\n",
      "           'outputs.fluency.fluency': 5,\n",
      "           'outputs.fluency.fluency_reason': 'The RESPONSE should get a Score '\n",
      "                                             'of 5 because it showcases '\n",
      "                                             'exceptional command of language, '\n",
      "                                             'sophisticated vocabulary, and '\n",
      "                                             'complex sentence structures, '\n",
      "                                             'making it coherent, cohesive, '\n",
      "                                             'and engaging.',\n",
      "           'outputs.fluency.fluency_result': 'pass',\n",
      "           'outputs.fluency.fluency_threshold': 3,\n",
      "           'outputs.fluency.gpt_fluency': 5,\n",
      "           'outputs.groundedness.gpt_groundedness': 3,\n",
      "           'outputs.groundedness.groundedness': 3,\n",
      "           'outputs.groundedness.groundedness_reason': 'The RESPONSE is '\n",
      "                                                       'grounded in the '\n",
      "                                                       'CONTEXT but includes '\n",
      "                                                       'unsupported additions '\n",
      "                                                       'that are not '\n",
      "                                                       'explicitly stated in '\n",
      "                                                       'the provided material.',\n",
      "           'outputs.groundedness.groundedness_result': 'pass',\n",
      "           'outputs.groundedness.groundedness_threshold': 3,\n",
      "           'outputs.relevance.gpt_relevance': 4,\n",
      "           'outputs.relevance.relevance': 4,\n",
      "           'outputs.relevance.relevance_reason': 'The RESPONSE fully addresses '\n",
      "                                                 'the QUERY with accurate and '\n",
      "                                                 'complete information, making '\n",
      "                                                 'it a complete response '\n",
      "                                                 'without additional insights.',\n",
      "           'outputs.relevance.relevance_result': 'pass',\n",
      "           'outputs.relevance.relevance_threshold': 3},\n",
      "          {'inputs.context': 'Desk. Wooden surface. Metal legs. Adjustable '\n",
      "                             'height. 48\" wide, 24\" deep, 28\" to 35\" tall. '\n",
      "                             'Holds 150 lbs.',\n",
      "           'inputs.ground_truth': 'The desk has a wooden surface and metal '\n",
      "                                  'legs. The height is adjustable. The '\n",
      "                                  'dimensions are 48\" wide, 24\" deep, 28\" to '\n",
      "                                  '35\" tall. The table can hold 50 lbs. ',\n",
      "           'inputs.query': 'Given the product specfication for the Contoso '\n",
      "                           'Home Furnishings Dining Desk, provide a product '\n",
      "                           'description.',\n",
      "           'inputs.response': 'Boost your productivity with this versatile '\n",
      "                              'desk, featuring a spacious wooden surface and '\n",
      "                              'sleek metal legs. With adjustable height '\n",
      "                              'ranging from 28 to 35 inches, this desk adapts '\n",
      "                              \"to your ideal working posture, whether you're \"\n",
      "                              'sitting or standing. The 48-inch width provides '\n",
      "                              'plenty of space for your computer, paperwork, '\n",
      "                              'and office essentials, while the sturdy '\n",
      "                              'construction supports up to 150 lbs. Perfect '\n",
      "                              'for home offices or creative workspaces.',\n",
      "           'outputs.fluency.fluency': 4,\n",
      "           'outputs.fluency.fluency_reason': 'The RESPONSE demonstrates '\n",
      "                                             'proficient fluency with clear, '\n",
      "                                             'coherent communication, varied '\n",
      "                                             'vocabulary, and well-structured '\n",
      "                                             'sentences, but it does not '\n",
      "                                             'exhibit the exceptional '\n",
      "                                             'sophistication required for the '\n",
      "                                             'highest score.',\n",
      "           'outputs.fluency.fluency_result': 'pass',\n",
      "           'outputs.fluency.fluency_threshold': 3,\n",
      "           'outputs.fluency.gpt_fluency': 4,\n",
      "           'outputs.groundedness.gpt_groundedness': 3,\n",
      "           'outputs.groundedness.groundedness': 3,\n",
      "           'outputs.groundedness.groundedness_reason': 'The RESPONSE is '\n",
      "                                                       'grounded in the '\n",
      "                                                       'CONTEXT but includes '\n",
      "                                                       'unsupported additions '\n",
      "                                                       'that are not '\n",
      "                                                       'explicitly stated in '\n",
      "                                                       'the provided material.',\n",
      "           'outputs.groundedness.groundedness_result': 'pass',\n",
      "           'outputs.groundedness.groundedness_threshold': 3,\n",
      "           'outputs.relevance.gpt_relevance': 3,\n",
      "           'outputs.relevance.relevance': 3,\n",
      "           'outputs.relevance.relevance_reason': 'The RESPONSE addresses the '\n",
      "                                                 'QUERY by providing a product '\n",
      "                                                 'description but lacks '\n",
      "                                                 'confirmation or explicit '\n",
      "                                                 'reference to the Contoso '\n",
      "                                                 'Home Furnishings Dining Desk '\n",
      "                                                 'specifications, making it '\n",
      "                                                 'incomplete.',\n",
      "           'outputs.relevance.relevance_result': 'pass',\n",
      "           'outputs.relevance.relevance_threshold': 3}],\n",
      " 'studio_url': None}\n",
      "[{\"name\": \"BleuScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"CoherenceEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"F1ScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"FluencyEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"GleuScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"GroundednessEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"MeteorScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"RelevanceEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"RougeScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"RougeType\", \"type\": \"EnumType\", \"fullType\": \"enum.EnumType\"}, {\"name\": \"SimilarityEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"azure\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"bleu_eval\", \"type\": \"BleuScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._bleu._bleu.BleuScoreEvaluator\"}, {\"name\": \"bleu_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"coherence_eval\", \"type\": \"CoherenceEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._coherence._coherence.CoherenceEvaluator\"}, {\"name\": \"coherence_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"context\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"credential\", \"type\": \"DefaultAzureCredential\", \"fullType\": \"azure.identity._credentials.default.DefaultAzureCredential\"}, {\"name\": \"evaluate\", \"type\": \"function\", \"fullType\": \"function\"}, {\"name\": \"f1_eval\", \"type\": \"F1ScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._f1_score._f1_score.F1ScoreEvaluator\"}, {\"name\": \"f1_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"fluency_eval\", \"type\": \"FluencyEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._fluency._fluency.FluencyEvaluator\"}, {\"name\": \"fluency_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"gleu_eval\", \"type\": \"GleuScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._gleu._gleu.GleuScoreEvaluator\"}, {\"name\": \"gleu_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"ground_truth\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"groundedness_eval\", \"type\": \"GroundednessEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._groundedness._groundedness.GroundednessEvaluator\"}, {\"name\": \"groundedness_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"json\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"load_dotenv\", \"type\": \"function\", \"fullType\": \"function\"}, {\"name\": \"meteor_eval\", \"type\": \"MeteorScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._meteor._meteor.MeteorScoreEvaluator\"}, {\"name\": \"meteor_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"model_config\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"os\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"path\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"pd\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"pprint\", \"type\": \"function\", \"fullType\": \"function\"}, {\"name\": \"query\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"relevance_eval\", \"type\": \"RelevanceEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._relevance._relevance.RelevanceEvaluator\"}, {\"name\": \"relevance_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"response\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"result\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"rouge_eval\", \"type\": \"RougeScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._rouge._rouge.RougeScoreEvaluator\"}, {\"name\": \"rouge_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"similarity_eval\", \"type\": \"SimilarityEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._similarity._similarity.SimilarityEvaluator\"}, {\"name\": \"similarity_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"token\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"token_provider\", \"type\": \"function\", \"fullType\": \"function\"}]\n",
      "[{\"name\": \"BleuScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"CoherenceEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"F1ScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"FluencyEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"GleuScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"GroundednessEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"MeteorScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"RelevanceEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"RougeScoreEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"RougeType\", \"type\": \"EnumType\", \"fullType\": \"enum.EnumType\"}, {\"name\": \"SimilarityEvaluator\", \"type\": \"ABCMeta\", \"fullType\": \"abc.ABCMeta\"}, {\"name\": \"azure\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"bleu_eval\", \"type\": \"BleuScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._bleu._bleu.BleuScoreEvaluator\"}, {\"name\": \"bleu_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"coherence_eval\", \"type\": \"CoherenceEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._coherence._coherence.CoherenceEvaluator\"}, {\"name\": \"coherence_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"context\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"credential\", \"type\": \"DefaultAzureCredential\", \"fullType\": \"azure.identity._credentials.default.DefaultAzureCredential\"}, {\"name\": \"evaluate\", \"type\": \"function\", \"fullType\": \"function\"}, {\"name\": \"f1_eval\", \"type\": \"F1ScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._f1_score._f1_score.F1ScoreEvaluator\"}, {\"name\": \"f1_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"fluency_eval\", \"type\": \"FluencyEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._fluency._fluency.FluencyEvaluator\"}, {\"name\": \"fluency_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"gleu_eval\", \"type\": \"GleuScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._gleu._gleu.GleuScoreEvaluator\"}, {\"name\": \"gleu_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"ground_truth\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"groundedness_eval\", \"type\": \"GroundednessEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._groundedness._groundedness.GroundednessEvaluator\"}, {\"name\": \"groundedness_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"json\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"load_dotenv\", \"type\": \"function\", \"fullType\": \"function\"}, {\"name\": \"meteor_eval\", \"type\": \"MeteorScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._meteor._meteor.MeteorScoreEvaluator\"}, {\"name\": \"meteor_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"model_config\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"os\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"path\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"pd\", \"type\": \"module\", \"fullType\": \"module\"}, {\"name\": \"pprint\", \"type\": \"function\", \"fullType\": \"function\"}, {\"name\": \"query\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"relevance_eval\", \"type\": \"RelevanceEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._relevance._relevance.RelevanceEvaluator\"}, {\"name\": \"relevance_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"response\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"result\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"rouge_eval\", \"type\": \"RougeScoreEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._rouge._rouge.RougeScoreEvaluator\"}, {\"name\": \"rouge_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"similarity_eval\", \"type\": \"SimilarityEvaluator\", \"fullType\": \"azure.ai.evaluation._evaluators._similarity._similarity.SimilarityEvaluator\"}, {\"name\": \"similarity_score\", \"type\": \"dict\", \"fullType\": \"dict\"}, {\"name\": \"token\", \"type\": \"str\", \"fullType\": \"str\"}, {\"name\": \"token_provider\", \"type\": \"function\", \"fullType\": \"function\"}]\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "import json\n",
    "\n",
    "path = \"performance-quality-data.jsonl\"\n",
    "\n",
    "result = evaluate(\n",
    "    data=path, # provide your data here\n",
    "    evaluators={\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"fluency\": fluency_eval\n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"default\": {\n",
    "            \"query\": \"${data.query}\",\n",
    "            \"response\": \"${data.response}\",\n",
    "            \"context\": \"${data.context}\",\n",
    "            \"ground_truth\": \"${data.ground_truth}\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the results with Pretty Print\n",
    "\n",
    "Now that we've run the evaluation, let's print the results using Pretty Print, which displays data in a structured and visually appealing way, making it easier to read and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the results as table\n",
    "\n",
    "We can also print the results as a table using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.response</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.relevance.relevance_result</th>\n",
       "      <th>outputs.relevance.relevance_threshold</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.groundedness.groundedness_result</th>\n",
       "      <th>outputs.groundedness.groundedness_threshold</th>\n",
       "      <th>outputs.fluency.fluency</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "      <th>outputs.fluency.fluency_result</th>\n",
       "      <th>outputs.fluency.fluency_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given the product specfication for the Contoso...</td>\n",
       "      <td>Sink into comfort with this stylish grey three...</td>\n",
       "      <td>Couch. Fabric upholstery. Three seats. Wooden ...</td>\n",
       "      <td>The couch has a wood frame with gray upholster...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with al...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is grounded in the CONTEXT but in...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given the product specfication for the Contoso...</td>\n",
       "      <td>Elevate your living space with this modern rou...</td>\n",
       "      <td>Coffee table. Glass top. Metal frame. Round. B...</td>\n",
       "      <td>The coffee table has a metal frame and glass t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is grounded in the CONTEXT but in...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE should get a Score of 5 because i...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the product specfication for the Contoso...</td>\n",
       "      <td>Boost your productivity with this versatile de...</td>\n",
       "      <td>Desk. Wooden surface. Metal legs. Adjustable h...</td>\n",
       "      <td>The desk has a wooden surface and metal legs. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE addresses the QUERY by providing ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is grounded in the CONTEXT but in...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inputs.query  \\\n",
       "0  Given the product specfication for the Contoso...   \n",
       "1  Given the product specfication for the Contoso...   \n",
       "2  Given the product specfication for the Contoso...   \n",
       "\n",
       "                                     inputs.response  \\\n",
       "0  Sink into comfort with this stylish grey three...   \n",
       "1  Elevate your living space with this modern rou...   \n",
       "2  Boost your productivity with this versatile de...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  Couch. Fabric upholstery. Three seats. Wooden ...   \n",
       "1  Coffee table. Glass top. Metal frame. Round. B...   \n",
       "2  Desk. Wooden surface. Metal legs. Adjustable h...   \n",
       "\n",
       "                                 inputs.ground_truth  \\\n",
       "0  The couch has a wood frame with gray upholster...   \n",
       "1  The coffee table has a metal frame and glass t...   \n",
       "2  The desk has a wooden surface and metal legs. ...   \n",
       "\n",
       "   outputs.relevance.relevance  outputs.relevance.gpt_relevance  \\\n",
       "0                            4                                4   \n",
       "1                            4                                4   \n",
       "2                            3                                3   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The RESPONSE fully addresses the QUERY with al...   \n",
       "1  The RESPONSE fully addresses the QUERY with ac...   \n",
       "2  The RESPONSE addresses the QUERY by providing ...   \n",
       "\n",
       "  outputs.relevance.relevance_result  outputs.relevance.relevance_threshold  \\\n",
       "0                               pass                                      3   \n",
       "1                               pass                                      3   \n",
       "2                               pass                                      3   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  3                                      3   \n",
       "1                                  3                                      3   \n",
       "2                                  3                                      3   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  \\\n",
       "0  The RESPONSE is grounded in the CONTEXT but in...   \n",
       "1  The RESPONSE is grounded in the CONTEXT but in...   \n",
       "2  The RESPONSE is grounded in the CONTEXT but in...   \n",
       "\n",
       "  outputs.groundedness.groundedness_result  \\\n",
       "0                                     pass   \n",
       "1                                     pass   \n",
       "2                                     pass   \n",
       "\n",
       "   outputs.groundedness.groundedness_threshold  outputs.fluency.fluency  \\\n",
       "0                                            3                        4   \n",
       "1                                            3                        5   \n",
       "2                                            3                        4   \n",
       "\n",
       "   outputs.fluency.gpt_fluency  \\\n",
       "0                            4   \n",
       "1                            5   \n",
       "2                            4   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \\\n",
       "0  The RESPONSE is well-articulated, coherent, an...   \n",
       "1  The RESPONSE should get a Score of 5 because i...   \n",
       "2  The RESPONSE demonstrates proficient fluency w...   \n",
       "\n",
       "  outputs.fluency.fluency_result  outputs.fluency.fluency_threshold  \n",
       "0                           pass                                  3  \n",
       "1                           pass                                  3  \n",
       "2                           pass                                  3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result[\"rows\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete resources\n",
    "\n",
    "If you've finished exploring Azure AI Services, delete the Azure resource that you created during the workshop.\n",
    "\n",
    "**Note**: You may be prompted to delete your deployed model(s) before deleting the resource group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
